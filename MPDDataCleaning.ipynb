{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook is used to clean the MPD (Milwaukee Police Department) dataset. Explanations will be included for some decisions in cleaning.\n",
    "\n",
    "# Dataset Description\n",
    "The first data set that will be evaluated in this notebook is stored in `mkecallswheader.csv`. This dataset comes from requesting the bulk data option from a [website](https://mpd.digitalpublicworks.com/?start=2019-01-05T00:00:00-06:00&end=2019-01-05T23:59:59.999999-06:00) that scrapes the milwaukee police department call logs found [here](https://itmdapps.milwaukee.gov/MPDCallData/) and stores them. This data is stored in a postgres server. The official .gov site shows that the data should have headers of call number, date/time, location, police district, nature of call, and status. The bulk data stored in the .csv file has a couple extra headers of id, inserted_at, updated_at, and point. These features will need to be dropped later on since they do not pertain to the data itself and are an artifact of how the data was stored. See [this link](https://city.milwaukee.gov/ImageLibrary/Groups/mpdAuthors/SOP/COMMUNICATIONS-2501.pdf) for more information about what certain codes mean.\n",
    "\n",
    "# Imports\n",
    "These are the libraries that will be relvant for cleaning this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Dataset\n",
    "The following sections walk through the steps used to clean the MPD dataset.\n",
    "\n",
    "## Load the Raw Data\n",
    "This section loads the raw data and examines how it is originally formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data = pd.read_csv(\"mkecallswheader.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above calls to the [`.head()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html), [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html), and [`.describe()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) methods it is possible to see that there are 10 total features. Of these features there are two features that are formatted as integers and eight features formatted as the default object that pandas imports non-numerical features as. From the object classified features there are a few that can be converted to new types. The time column should be formatted as a date time object. District should be converted to a numerical categorical value. Nature and status should be converted to categorical features. Location should be kept as an object feature. More features should be extracted from the location in order to draw further observations. Both street name and street suffix would be good features to extract. Stack overflow [helped](https://stackoverflow.com/a/43427677) with showing null counts in the info command as well.\n",
    "\n",
    "## Drop Postgres Features\n",
    "\n",
    "All of the postgres features that are not part of the data can be dropped in the next step. These are the headers of id, inserted_at, updated_at, and point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data = mpd_data.drop('id', axis=1)\n",
    "mpd_data = mpd_data.drop('inserted_at', axis=1)\n",
    "mpd_data = mpd_data.drop('updated_at', axis=1)\n",
    "mpd_data = mpd_data.drop('point', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Time feature\n",
    "\n",
    "The time should be converted to a pandas datetime object. The feature name should also be changed to reflect that the feature contains both date and time information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data['datetime'] = pd.to_datetime(mpd_data['time'], infer_datetime_format=True)\n",
    "mpd_data = mpd_data.drop('time', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Unique Values for Nature, Status, and District\n",
    "\n",
    "The nature, status, and district features will be examined for unique values and converted into categorical features.\n",
    "\n",
    "### Examine the District Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data['district'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data['district'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a value counts on the different districts shows that there are more than the expected number of police districts in the city of Milwaukee present in the data. There should only be districts one through seven. Instead the data contains more districts than expected. These districts will be converted into categorical anyways as their entries will be useful for some observations. The erraneous districts will likely be ignored when drawing district based conclusions as it is not known what the other districts mean. District will be converted to a categorical with 36 different categories.\n",
    "\n",
    "### Examine the Nature Feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data['nature'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data['nature'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mpd_data['nature'].value_counts().sort_index()\n",
    "a[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 317 unique natures present in the dataset. It will be necessary to define a few specific natures to use as targets due to the large number. Some natures are also repeated such as SUBJ WITH GUN and SUBJ W/GUN. In this case the larger and more prevalent of the two natures will be used. The following list of natures will be focused on:\n",
    "- TRAFFIC STOP        401644\n",
    "- SHOTSPOTTER          65381\n",
    "- SHOTS FIRED          47331\n",
    "- SUBJ WITH GUN        44509\n",
    "- SUBJ WITH WEAPON     30101\n",
    "- RECK USE OF WEAP     17524\n",
    "- SHOOTING             7054\n",
    "\n",
    "The number next to the nature denotes how many occurances of that nature were found out of the 4027695 total entries in the dataset. The Entries to focus on are divided into two categories. The fist is the traffic related crimes and the second is the gun and weapon related crimes. These will be focused by adding two boolean features to the data which will denote their presence or absence.\n",
    "\n",
    "The nature feature also contains some anomalous values such as \n",
    "- .                      20\n",
    "- 0                       1\n",
    "- 1 BLOCK NORTH OF        2\n",
    "- 1301                    1\n",
    "- 1359                    1\n",
    "- 1603                    1\n",
    "- 1733                    1\n",
    "- 230 N 37TH ST           1\n",
    "- 2532                    1\n",
    "- 2831 N 21ST             1\n",
    "- 3                       1\n",
    "- 3410                    2\n",
    "\n",
    "These values will be retained and included as part of the categorical conversion. This is because they will not be as relevant due to specific features being targeted.\n",
    "\n",
    "### Examine the Status Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data['status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The status feature looks like it will work very well as a category as is. Most of the counts also look good. The main focus would be on those that occur more than 40000 times overall in the data. This is due to the drop in occurances of almost an order of magnitude after that point.\n",
    "\n",
    "### Cleaning the Nature Feature\n",
    "\n",
    "The first step for cleaning nature is to define what values of the nature feature will make up the traffic and weapon crimes. Once that is completed these values can be used to create new features that denote this. After that The nature feature can be turned into a categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Shape Before: %s\" % ((mpd_data.shape), ))\n",
    "target_traffic_crimes_labels = ['TRAFFIC STOP']\n",
    "target_weapon_crimes_labels = ['SHOTSPOTTER', 'SHOTS FIRED', 'SHOTS FIRED-DV', \n",
    "'SUBJ WITH GUN', 'SUBJ W/GUN', 'SUBJ WITH GUN-DV', 'SUBJ WITH WEAPON', \n",
    "'SUBJ W/WEAP', 'SUBJ W/WEAPON-DV', 'RECK USE OF WEAP', 'SHOOTING']\n",
    "mpd_data['traffic_crime'] = mpd_data['nature'].isin(target_traffic_crimes_labels)\n",
    "mpd_data['weapon_crime'] = mpd_data['nature'].isin(target_weapon_crimes_labels)\n",
    "print(\"Data Shape After: %s\" % ((mpd_data.shape), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data['nature'] = mpd_data['nature'].astype(\"category\")\n",
    "mpd_data['nature'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the District and Status Features\n",
    "\n",
    "The district and status features appeared mostly fine above. Because of this they will just be turned directly into categorical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data['district'] = mpd_data['district'].astype(\"category\")\n",
    "mpd_data['district'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mpd_data['status'] = mpd_data['status'].astype('category')\n",
    "mpd_data['status'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Examine Location\n",
    "\n",
    "The location feature can be used to create many new features that will be easier to use. Currently the location values are in one of two formats. The first format is $HouseNumber$ $StreetName$ $StreetType$,MKE. The second format is $StreetName_1$ $StreetType_1$ / $StreetName_2$ $StreetType_2$,MKE. The second format occurs when the location is on the corner of two streets. A categorical feature will be created to denote if an entry is a corner or not. The attributes of each street in the location will be recorded. Null or NaN values will be recorded where there are no values. There will be no house number for addresses that are corners and no secondary names or types for addresses that are not corners. Overall the following features will be added:\n",
    "- isCorner\n",
    "- houseNumber\n",
    "- primaryStreetName\n",
    "- primaryStreetSuffix\n",
    "- secondaryStreetName\n",
    "- secondaryStreetSuffix\n",
    "\n",
    "### Method to Extract Addresses\n",
    "\n",
    "The first step to clean location is to create a method to extract addresses from the raw location strings. This method will then be tested on some example cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_street_info(address: str) -> list:\n",
    "    \"\"\"\n",
    "    This method will take in a string representing an address and will return the information present in that address.\n",
    "    Some example addresses are as follows:\n",
    "        0             7420 W GOOD HOPE RD,MKE\n",
    "        1                  1421 N 27TH ST,MKE\n",
    "        2                  4054 N 71ST ST,MKE\n",
    "        3                245 W LINCOLN AV,MKE\n",
    "        4                 1721 W CANAL ST,MKE\n",
    "        5         E WRIGHT ST / N WEIL ST,MKE\n",
    "        6                  9010 N 95TH ST,MKE\n",
    "    :param address: the string passed in representing the address\n",
    "    :return: a list containing two tuples. Each tuple will be an addres of the form (houseNumber, streetName, streetType)\n",
    "    :auth: Grant Fass\n",
    "    :since: 8 February 2022\n",
    "    \"\"\"\n",
    "    street_type_lookup = [\"ALY\", \"ANX\", \"ARC\", \"AVE\", \"BYU\", \"BCH\", \"BND\", \"BLF\", \"BLFS\", \"BTM\", \"BLVD\", \"BR\", \"BRG\", \"BRK\", \"BRKS\", \"BG\", \"BGS\", \"BYP\", \"CP\", \"CYN\", \"CPE\",\n",
    "                          \"CSWY\", \"CTR\", \"CTRS\", \"CIR\", \"CIRS\", \"CLF\", \"CLFS\", \"CLB\", \"CMN\", \"CMNS\", \"COR\", \"CORS\", \"CRSE\", \"CT\", \"CTS\", \"CV\", \"CVS\", \"CRK\", \"CRES\", \"CRST\", \n",
    "                          \"XING\", \"XRD\", \"XRDS\", \"CURV\", \"DL\", \"DM\", \"DV\", \"DR\", \"EST\", \"ESTS\", \"EXPY\", \"EXT\", \"EXTS\", \"FALL\", \"FLS\", \"FRY\", \"FLD\", \"FLDS\", \"FLT\", \"FLTS\", \n",
    "                          \"FRD\", \"FRDS\", \"FRST\", \"FRG\", \"FRGS\", \"FRK\", \"FRKS\", \"FT\", \"FWY\", \"GDN\", \"GDNS\", \"GTWY\", \"GLN\", \"GLNS\", \"GRN\", \"GRNS\", \"GRV\", \"GRVS\", \"HBR\", \"HBRS\", \n",
    "                          \"HVN\", \"HTS\", \"HWY\", \"HL\", \"HLS\", \"HOLW\", \"INLT\", \"IS\", \"ISS\", \"ISLE\", \"JCT\", \"JCTS\", \"KY\", \"KYS\", \"KNL\", \"KNLS\", \"LK\", \"LKS\", \"LAND\", \"LNDG\", \"LN\",\n",
    "                          \"LGT\", \"LGTS\", \"LF\", \"LCK\", \"LCKS\", \"LDG\", \"LOOP\", \"MALL\", \"MNR\", \"MNRS\", \"MDW\", \"MDWS\", \"MEWS\", \"ML\", \"MLS\", \"MSN\", \"MTWY\", \"MT\", \"MTN\", \"MTNS\", \n",
    "                          \"NCK\", \"ORCH\", \"OVAL\", \"OPAS\", \"PARK\", \"PKWY\", \"PASS\", \"PSGE\", \"PATH\", \"PIKE\", \"PNE\", \"PNES\", \"PL\", \"PLN\", \"PLNS\", \"PLZ\", \"PT\", \"PTS\", \"PRT\", \"PRTS\", \n",
    "                          \"PR\", \"RADL\", \"RAMP\", \"RNCH\", \"RPD\", \"RPDS\", \"RST\", \"RDG\", \"RDGS\", \"RIV\", \"RD\", \"RDS\", \"RTE\", \"ROW\", \"RUE\", \"RUN\", \"SHL\", \"SHLS\", \"SHR\", \"SHRS\", \n",
    "                          \"SKWY\", \"SPG\", \"SPGS\", \"SPUR\", \"SQ\", \"SQS\", \"STA\", \"STRA\", \"STRM\", \"ST\", \"STS\", \"SMT\", \"TER\", \"TRWY\", \"TRCE\", \"TRAK\", \"TRFY\", \"TRL\", \"TRLR\", \"TUNL\",\n",
    "                          \"TPKE\", \"UPAS\", \"UN\", \"UNS\", \"VLY\", \"VLYS\", \"VIA\", \"VW\", \"VWS\", \"VLG\", \"VLGS\", \"VL\", \"VIS\", \"WALK\", \"WALL\", \"WAY\", \"WAYS\", \"WL\", \"WLS\", \"AV\"]\n",
    "    # this is used primarily for error checking\n",
    "    unmatched_suffix = \"\"\n",
    "    # remove the ,MKE suffix from the location if present\n",
    "    address = address.removesuffix(\",MKE\")\n",
    "    # Array containing the seperate addresses in the passed entry\n",
    "    addresses = []\n",
    "    # Check if the entry contains a / or not.\n",
    "    # The presence of a / denotes the entry as a corner with two streets present\n",
    "    # For example: N HUMBOLDT AV / E NORTH AV\n",
    "    if ('/' in address):\n",
    "        addresses = address.split(' / ')\n",
    "    else:\n",
    "        addresses = [address]\n",
    "    \n",
    "    # now perform opperations for each address\n",
    "    # print(addresses)\n",
    "    out = []\n",
    "    for a in addresses:\n",
    "        # Set up the values to be returned\n",
    "        house_number = None\n",
    "        street = None\n",
    "        street_suffix = None\n",
    "        # split appart the address on spaces\n",
    "        s = a.split(' ')\n",
    "        # Check if the first cell is a nueric. This would be the house number if it is a numeric\n",
    "        if s[0].isnumeric():\n",
    "            # house number present\n",
    "            house_number = int(s[0])\n",
    "            street = ' '.join(s[1:-1]) # use -1 since last index is exclusive\n",
    "        else:\n",
    "            street = ' '.join(s[0:-1])\n",
    "        # update the street suffix based on the last entry in the array\n",
    "        if s[-1] in street_type_lookup:\n",
    "            street_suffix = s[-1]\n",
    "        # add the entries into the return field\n",
    "        out.append((house_number, street, street_suffix))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data['location'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  E WRIGHT ST / N WEIL ST,MKE\n",
    "get_street_info(mpd_data['location'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1421 N 27TH ST,MKE\n",
    "get_street_info(mpd_data['location'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to Further Extract Location Data\n",
    "\n",
    "The next step is to define a method that will take the list of addresses returned by the previous method and combine them into a single list. This method will also be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_street_data_as_array(location: list) -> list:\n",
    "    \"\"\"\n",
    "    Method to take in a location that contains up to two streets and combine it into one list for output.\n",
    "    The location is an array of tuples up to two in length.\n",
    "    Each tuple will have 3 entries of the form (houseNumber, streetName, streetSuffix).\n",
    "    If two entries are present then the location is a corner.\n",
    "    The output list will be of the form [isCorner, houseNumber, primaryStreetName, primaryStreetSuffix, secondaryStreetName, secondaryStreetSuffix]\n",
    "    :param location: an array of tuples up to two in length.\n",
    "    :return: list will be of the form [isCorner, houseNumber, primaryStreetName, primaryStreetSuffix, secondaryStreetName, secondaryStreetSuffix]\n",
    "    :auth: Grant Fass\n",
    "    :since: 8 February 2022\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(location) == 1:\n",
    "        # is not corner\n",
    "        location_vals = list(location[0])\n",
    "        return [False, location_vals[0], location_vals[1], location_vals[2], None, None]\n",
    "    else:\n",
    "        # is corner\n",
    "        primary_location_vals = list(location[0])\n",
    "        secondary_location_vals = list(location[1])\n",
    "        return [True, None, primary_location_vals[1], primary_location_vals[2], \n",
    "        secondary_location_vals[1], secondary_location_vals[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_street_data_as_array(get_street_info(mpd_data['location'][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_street_data_as_array(get_street_info(mpd_data['location'][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the Methods to Extract Location Data\n",
    "\n",
    "The above methods will be applied in sequence to extract the location data into a new dataframe. The features will then have their types set correctly and inspected to verify that the process worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tolist() is needed since the output is a ndarray of lists.\n",
    "street_data = mpd_data[\"location\"].map(get_street_info).map(get_street_data_as_array).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"isCorner\", \"houseNumber\", \"primaryStreetName\", \"primaryStreetSuffix\", \"secondaryStreetName\", \"secondaryStreetSuffix\"]\n",
    "mpd_location_data = pd.DataFrame(street_data, columns=header)\n",
    "mpd_location_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_location_data['primaryStreetSuffix'] = mpd_location_data['primaryStreetSuffix'].astype('category')\n",
    "mpd_location_data['primaryStreetName'] = mpd_location_data['primaryStreetName'].astype('category')\n",
    "mpd_location_data['secondaryStreetSuffix'] = mpd_location_data['secondaryStreetSuffix'].astype('category')\n",
    "mpd_location_data['secondaryStreetName'] = mpd_location_data[\"secondaryStreetName\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_location_data.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_location_data['isCorner'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recombine the Location Data\n",
    "\n",
    "The locations have now been properly extracted into their own seperate features. These features must now be added back to the overall MPD dataframe. Out of the 4027695 entries there were 549725 locations that are corners and 3477970 that are not corners. The datasets will be combined using an inner join and [`pd.concat`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html). The original location feature will be dropped once the outer merge is completed as it will become irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MPD Data Shape Before: %s\" % ((mpd_data.shape), ))\n",
    "print(\"MPD Location Data Shape Before: %s\" % ((mpd_location_data.shape), ))\n",
    "mpd_data = pd.concat([mpd_data, mpd_location_data], join='outer', axis=1)\n",
    "mpd_data = mpd_data.drop('location', axis=1)\n",
    "print(\"MPD Data Shape After: %s\" % ((mpd_data.shape), ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "At this point the MPD dataset is done being cleaned. The last steps are to show the final outputs of the [`.head()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html), [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html), and [`.describe()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) methods and output the cleaned data to a new csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_data.to_csv(\"mpd_data_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
