{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42f1e02",
   "metadata": {},
   "source": [
    "# Analyzing Milwaukee Police Call Data and Weather Data\n",
    "### Grant Fass and Chris Hubbell\n",
    "\n",
    "## Introduction\n",
    "Across the world, there are many crimes commited every hour. One of the greatest challenges is reducing crime and maintaining safety for citizens. Part of preventing crime relies on the reporting of it by citizens. If nobody informs the police, the police are unable to act. This is why reporting crimes and incidents is so important, especially when people's lives are in danger. In Wisconsin, Milwaukee Police Department (MPD) releases data regarding all of their dispatch calls, which we have been able to get since 2016. This allows for analyzing trends of crime reporting over time as well as as it relates to other factors. In 2010, Milwaukee installed a new system for detecting gun shots called ShotSpotter, which was expanded into more neighborhoods in 2014. This system is capable of detecting when a shot is fired and where it was to a high degree of accuracy. The data consists of both ShotSpotter calls as well as Shots Fired calls. The key difference is that Shots Fired are calls from people and ShotSpotter are automatic.\n",
    "\n",
    "## Research Questions:\n",
    "- Is there a significant difference between the distribution of shots spotted over time and calls for shots fired?\n",
    "- Is there a significant difference in the proportion of calls that were unable to be located for shots fired calls compared to shots spotted?\n",
    "- Does the Proportion of shots spotted and fired correlate with certain dates including holidays and events?\n",
    "- Does the number of calls correlate with certain weather conditions?\n",
    "- ~~Is it possible to predict number of calls based on location and district?~~\n",
    "- Is it possible to predict the nature of a call based on its location and district?\n",
    "\n",
    "## Hypotheses:\n",
    "- There are significantly more shots spotted than calls about shots fired.\n",
    "- Significantly more shots fired calls are unable to be located than shots spotted.\n",
    "- There will be significantly more shots spotted calls on July 4th, Dec. 31st, and Jan 1st than normal days.\n",
    "- There will be significantly less shots fired calls on holidays than normal days.\n",
    "- There are significantly more calls on days with clear weather than inclement weather.\n",
    "- There are significantly more calls on days around 75 degrees than there are on days around 95 or 55 degrees.\n",
    "- ~~The number of calls will be able to be predicted based on location and district.~~\n",
    "- The type of call will be unable to be predicted based on location and district.\n",
    "\n",
    "## Notes:\n",
    "One of the research questions and one of the hypotheses is striked out. This is because it was not possible to come up with a good method for measuring this in time.\n",
    "\n",
    "# Imports\n",
    "These are the libraries that will be relvant for working with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101fbc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import chi2_contingency\n",
    "from IPython.display import Image\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from sklearn.metrics import roc_curve, plot_roc_curve, precision_recall_curve, plot_precision_recall_curve\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sns.set(rc={\"figure.figsize\":(12, 6)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1b2989",
   "metadata": {},
   "source": [
    "# Loading the Data\n",
    "This section is used to load the data and make sure that all of the features have been formatted using the correct types. This data is ready for use since it has already been cleaned in another notebook. The MPDDataCleaning notebook was used to clean the MPD (Milwaukee Police Department) dataset. The WeatherDataCleaning notebook was used to clean the weather dataset. These two datasets were then combined in the DatasetCombining notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e4cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101da9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de50b60f",
   "metadata": {},
   "source": [
    "## Revising Feature Types\n",
    "Calling the [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html) command shows that there are a number of features that are improperly formatted. The district, nature, status, primaryStreetName, primaryStreetSuffix, secondaryStreetName, secondaryStreetSuffix, and weatherDesc all need to become categorical features. The datetime feature needs to be changed to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b3120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['district'] = df['district'].astype('category')\n",
    "# df['nature'] = df['nature'].astype('category')\n",
    "df['status'] = df['status'].astype('category')\n",
    "df['primaryStreetName'] = df['primaryStreetName'].astype('category')\n",
    "df['primaryStreetSuffix'] = df['primaryStreetSuffix'].astype('category')\n",
    "df['secondaryStreetName'] = df['secondaryStreetName'].astype('category')\n",
    "df['secondaryStreetSuffix'] = df['secondaryStreetSuffix'].astype('category')\n",
    "df['weatherDesc'] = df['weatherDesc'].astype('category')\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], infer_datetime_format=True)\n",
    "df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True)\n",
    "df['shots_nature'] = df['shots_nature'].astype('category')\n",
    "df['top_natures'] = df['top_natures'].astype('category')\n",
    "df['top_districts'] = df['top_districts'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f44df",
   "metadata": {},
   "source": [
    "## Examining The Loaded Data\n",
    "The data should now be in the proper types. This will be examined using the [`.head()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html), [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html), and [`.describe()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafc4be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9a1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d44605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de42d440",
   "metadata": {},
   "source": [
    "## TODO: Explain the Loaded Data\n",
    "\n",
    "\n",
    "# Examining the Research Questions\n",
    "This section will seek to examine the research questions outlined at the top of the notebook by exploring the data through the use of both graphs and statistical tests. This section will use a few possible different statistical tests based on the scenario and shape of the data. The [Kolmogorov-Smirnov test](http://www.mit.edu/~6.s085/notes/lecture5.pdf) can be used to test if two arbitrary distributions are the same. [It does not require the data being normally distributed](http://statstutor.ac.uk/resources/steps-glossary/glossary/nonparametric.html#:~:text=The%20Kolmogorov%2DSmirnov%20test%20does,Squared%20Goodness%20of%20Fit%20Test.&text=The%20Kruskal%2DWallis%20test%20is,compare%20three%20or%20more%20samples.&text=It%20is%20the%20analogue%20to,used%20in%20analysis%20of%20variance.). The [two sample t-test](https://www.jmp.com/en_us/statistics-knowledge-portal/t-test/two-sample-t-test.html) can be used to test if the means of two distributions are the same. The [Kruskal-Wallis test](https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance) can be used to determine if two samples come from the same distribution. The Kruskal-Wallis test does require that the data be normally distributed though. The [chi-squared test](https://stats.oarc.ucla.edu/spss/whatstat/what-statistical-analysis-should-i-usestatistical-analyses-using-spss/#:~:text=A%20chi%2Dsquare%20test%20is,relationship%20between%20two%20categorical%20variables.) will be used to test if there is a relationship between two categorical variables. The research questions that seek to determine if prediction is possible will be examined in a later section on building machine learning models.\n",
    "\n",
    "## Preparation\n",
    "Creating the graphs and running the statistical tests in the following sections will be much easier if some features are added to the dataset. Some of the key features include extracting different values of the datetime feature such as day, week, month, and year. This will allow for the exploration of different granularity levels. Some of the graphs use help from [this](https://www.statology.org/seaborn-legend-outside/) for moving the legend outside of the graph, and from [this](https://stackoverflow.com/a/60679315) for plotting multiple categories (fix legend not showing). [This](https://stackoverflow.com/questions/9847213/how-do-i-get-the-day-of-week-given-a-date) stackoverflow post helped with extracting day of the week from datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59a3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nature_remap(n: str) -> str:\n",
    "#     \"\"\"\n",
    "#     method to remap nature to be just 3 categories. SHOTSPOTTER, SHOTS FIRED, and OTHER\n",
    "#     :param n: the nature to remap\n",
    "#     :return: the remapped nature\n",
    "#     \"\"\"\n",
    "#     if n not in ['SHOTSPOTTER', 'SHOTS FIRED']:\n",
    "#         return 'OTHER'\n",
    "#     else:\n",
    "#         return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nature_remap_top_50(nature: str, unique_natures: list) -> str:\n",
    "#     \"\"\"\n",
    "#     method to remap nature to be just 3 categories. SHOTSPOTTER, SHOTS FIRED, and OTHER\n",
    "#     :param nature: the nature to remap\n",
    "#     :return: the remapped nature\n",
    "#     \"\"\"\n",
    "#     if nature not in unique_natures[0:50]:\n",
    "#         return 'OTHER'\n",
    "#     else:\n",
    "#         return nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f2d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def district_remap(value: str) -> str:\n",
    "#     \"\"\"\n",
    "#     method to remap district to include the 7 Milwaukee police districts \n",
    "#     and one OTHER district.\n",
    "#     :param value: the value of district to remap\n",
    "#     :return: the remapped value of district\n",
    "#     \"\"\"\n",
    "#     if value != value: # https://stackoverflow.com/questions/944700/how-can-i-check-for-nan-values\n",
    "#         return 'EMPTY'\n",
    "#     if value not in ['1', '2', '3', '4', '5', '6', '7']:\n",
    "#         return 'OTHER'\n",
    "#     else:\n",
    "#         return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_50_natures = list(df['nature'].value_counts().index)[0:50]\n",
    "# df['minNature'] = df['nature'].map(nature_remap)\n",
    "# df['minNature'] = df['minNature'].astype('category')\n",
    "# df['top_50_natures'] = df.apply(lambda t: nature_remap_top_50(t['nature'], top_50_natures), axis=1)\n",
    "# df['top_50_natures'] = df['top_50_natures'].astype('category')\n",
    "# df['top_districts'] = df['district'].astype('object').map(district_remap)\n",
    "# df['top_districts'] = df['top_districts'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa20759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['date'] = df['datetime'].map(lambda t: t.date()) # Represents only the date with no time of day attached.\n",
    "# df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True) # Change the type to a datetime (all the time values will be 0) this is so it can be graphed easier\n",
    "# df['year'] = df['datetime'].map(lambda t: t.year) # Represents year\n",
    "# df['month'] = df['datetime'].map(lambda t: t.month) # Represents month of the year\n",
    "# df['week'] = df['datetime'].map(lambda t: t.week) # Represents week of the year\n",
    "# df['day'] = df['datetime'].map(lambda t: t.day) # Represents day of the month\n",
    "# df['hour'] = df['datetime'].map(lambda t: t.hour) # Represents hour of the day\n",
    "# df['weekday'] = df['datetime'].map(lambda t: t.weekday()) # Monday is 0 and Sunday is 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c109a699",
   "metadata": {},
   "source": [
    "A filtered dataframe can be created containing only the entries for weapon crime. Extra categorical values must be removed when filtering down a categorical feature with many values (such as nature). This can be done by redefining the type as a category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shots_df = df[df['top_natures'].isin(['SHOTSPOTTER', 'SHOTS FIRED'])][['top_natures', 'status', 'datetime', 'date', 'year', 'month', 'week', 'day', 'hour', 'weekday']].copy(deep=True)\n",
    "shots_df['top_natures'] = shots_df['top_natures'].astype('object').astype('category')\n",
    "shots_df['notLocated'] = shots_df['status']=='Unable to Locate Complainant'\n",
    "print(\"Data Shape After: %s\" % ((shots_df.shape), ))\n",
    "shots_df.head(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf65c5b",
   "metadata": {},
   "source": [
    "## Research Question 1: Is There a Significant Difference Between the Distribution of Shots Spotted Over Time and Calls for Shots Fired?\n",
    "The first step in answering this research question is to graph the distributions of shots spotted and shots fired over time. These can be compared over different possible time ranges. Some of the possible time ranges for comparisons include day of the week, day of the month, week of the year, month of the year, and daily over the entire time range of the dataset. These graphs can then be looked at to predict if a dataset is normally distributed or not. The outcome of this prediction will then determine what statistical test should be used.\n",
    "\n",
    "### Graphing Shots Spotted vs. Shots Fired Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a679596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of shots spotted vs shots fired over time\n",
    "# Graph is not the best but is the most legible out of possible formats.\n",
    "uses = shots_df['top_natures'].unique()\n",
    "# plt.figure(figsize=(7,7))\n",
    "ax = plt.axes()\n",
    "for use in uses:\n",
    "    sns.kdeplot(x=shots_df[\"date\"], hue=shots_df[shots_df['top_natures']==use][\"top_natures\"], ax=ax, common_norm=False, multiple=\"layer\", alpha=1, label=use)\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "ax.set_title(\"Shots Spotted vs. Shots Fired Calls Over Time\")\n",
    "ax.set_xlabel('Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17644d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"year\", hue=\"top_natures\", data=shots_df)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_title('Number of Shotspotter vs Shots Fired calls by Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"month\", hue=\"top_natures\", data=shots_df)\n",
    "ax.set_xlabel('Month of the Year')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_title('Number of Shotspotter vs Shots Fired calls by Month of the Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb76c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"week\", hue=\"top_natures\", data=shots_df)\n",
    "ax.set_xlabel('Week of the Year')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_title('Number of Shotspotter vs Shots Fired calls by Week of the Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adc7cd5",
   "metadata": {},
   "source": [
    "This graph shows that there is some anomalous data since there are not 53 weeks in a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d10d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"day\", hue=\"top_natures\", data=shots_df)\n",
    "ax.set_xlabel('Day of the Month')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_title('Number of Shotspotter vs Shots Fired calls by Day of the Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa1f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"hour\", hue=\"top_natures\", data=shots_df)\n",
    "ax.set_xlabel('Hour of the Day')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_title('Number of Shotspotter vs Shots Fired calls by Hour of the Day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8933bc5",
   "metadata": {},
   "source": [
    "### Performing Statistical Tests to Determine if the Distributions are Simmilar.\n",
    "The above graphs show that neither the distribution of shots fired or shots spotted are normal for any time increment. This means that the Kruskal-Wallis statistical test cannot be used. The [Kolmogorov-Smirnov test, from the scipy stats library,](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kstest.html) will be used to determine if the number of shots spotted and shots called are simmilar. The [two sample version](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ks_2samp.html#scipy.stats.ks_2samp) of the test will be used. The 'two sided' mode will be used for this test. This defines the null hypothesis to be that the two distributions are identical and the alternative to be that they are not identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p = ks_2samp(shots_df[shots_df['top_natures'] == 'SHOTSPOTTER']['date'], shots_df[shots_df['top_natures'] == 'SHOTS FIRED']['date'], alternative='two-sided')\n",
    "print('The p-value for the Kolmogorov-Smirnov test between the distributions of shots spotted and shots fired over time is: %e' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c1d4d",
   "metadata": {},
   "source": [
    "### Conclusions for Research Question 1\n",
    "#### TODO\n",
    "run more tests?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e17de23",
   "metadata": {},
   "source": [
    "## Research Question 2: Is There a Significant Difference in the Proportion of Calls That Were Unable to be Located for Shots Fired Calls Compared to Shots Spotted?\n",
    "\n",
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77729374",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(data=pd.crosstab(shots_df['top_natures'], shots_df['notLocated']), annot=True)\n",
    "ax.set_xlabel('Unable to be Located')\n",
    "ax.set_title('Calls Unable to be Located for Shots Spotted and Shots Fired')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3508d6",
   "metadata": {},
   "source": [
    "### Performing Statistical Test\n",
    "The [Chi-Squared test of independance](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html) is used to determine if there is a relationship between two or more variables by determining if they have a simmilar distribution. The [Chi-Squared test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html#scipy.stats.chisquare) is used to test if one feature has a specific distribution. This means the test of independance will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868bd9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination_counts = original_cleaned_data[[\"type\",target]].groupby(by=[\"type\",target]).size().unstack(level=0).fillna(0)\n",
    "# chi2, p, _, _ = stats.chi2_contingency(combination_counts)\n",
    "compared = ['top_natures', 'notLocated']\n",
    "_, p, _, _ = stats.chi2_contingency(shots_df[compared].groupby(by=compared).size().unstack(level=0).fillna(0))\n",
    "print('The p-value for the test of independance between nature and notLocated is: %e' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd2657",
   "metadata": {},
   "source": [
    "### Conclusions for Research Question 2\n",
    "#### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d96b7",
   "metadata": {},
   "source": [
    "## Research Question 3: Does the Proportion of Shots Spotted and Shots Fired Correlate With Certain Dates Including Holidays and Events?\n",
    "The following holdays will be used in this comparison:\n",
    "- Independance day: July 4th, any year\n",
    "- Christmas: December 25th, any year\n",
    "- New Years Eve: December 31st, any year\n",
    "- New Years: January 1st, any year\n",
    "- Valentines Day: February 14th, any year\n",
    "- Halloween: October 31st, any year\n",
    "- Saint Patrick's Day: March 17th, any year\n",
    "\n",
    "Thanksgiving will not be compared because it occurs on different days each year. Black friday will not be compared for the same reason. Due to the nature of this question it will likely be easiest to examine this question on a monthly basis instead of on a yearly basis.\n",
    "\n",
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4601637",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"day\", hue='top_natures', data=shots_df[shots_df['month'] == 7]) # 7 denotes the month of July\n",
    "# ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "ax.set_xlabel('Day in July')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_title('Number of Calls Per Day in July')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100eb85e",
   "metadata": {},
   "source": [
    "This graph shows that there are a lot more calls for shots fired than normal on the fourth of July. This is likely due to people mistaking the sounds of fireworks in the distance for gunshots. This is likely reinforced by the shotspotter calls remaining much lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b146ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"day\", hue='top_natures', data=shots_df[shots_df['month'] == 12]) # 12 denotes the month of December\n",
    "# ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "ax.set_xlabel('Day in December')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_title('Number of Calls Per Day in December')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7da32e",
   "metadata": {},
   "source": [
    "This graph shows that there is a large spike in shots fired and shots spotted on new years eve. It also shows that there may be a slight increase around Christmas. The slight increase around christmas may not be significant though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de5677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"day\", hue='top_natures', data=shots_df[shots_df['month'] == 1]) # 1 denotes the month of January\n",
    "# ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "ax.set_xlabel('Day in January')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_title('Number of Calls Per Day in January')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d003951",
   "metadata": {},
   "source": [
    "This graph shows that there is a massive increase in calls for shots spotted and shots fired on new years day. There are more than four times as many calls on the first compared to other days of the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d99fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"day\", hue='top_natures', data=shots_df[shots_df['month'] == 2]) # 2 denotes the month of February\n",
    "# ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "ax.set_xlabel('Day in February')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_title('Number of Calls Per Day in February')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84775fb6",
   "metadata": {},
   "source": [
    "This graph shows that there may actually be a decrease in calls around valentines day compared to the rest of the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"day\", hue='top_natures', data=shots_df[shots_df['month'] == 3]) # 3 denotes the month of March\n",
    "# ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "ax.set_xlabel('Day in March')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_title('Number of Calls Per Day in March')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce9bddd",
   "metadata": {},
   "source": [
    "This graph is very jumpy which makes it hard to draw any conclusions from the graph alone. It does seem that there is not a significant difference for saint patrics day compared to other days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ba7f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"day\", hue='top_natures', data=shots_df[shots_df['month'] == 10]) # 10 denotes the month of October\n",
    "# ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "ax.set_xlabel('Day in October')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_title('Number of Calls Per Day in October')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890e348",
   "metadata": {},
   "source": [
    "This graph does not seem to show a large increase in shots spotted or shots fired on Halloween."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8087c",
   "metadata": {},
   "source": [
    "### Statistical Tests\n",
    "#### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e86832",
   "metadata": {},
   "source": [
    "## Research Question 4: Does the Number of Calls Correlate With Certain Weather Conditions?\n",
    "<!-- could change to a heatmap where there are 3 columns. one for shot spotted, one for shot fired, and one for other. Compare the distribution of shot spotted vs other, compare shot fired vs other.  -->\n",
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c86b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(y=\"weatherDesc\", data=df)\n",
    "# ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "ax.set_xlabel('Number of Calls')\n",
    "ax.set_ylabel('Weather Description')\n",
    "ax.set_title('Number of Calls vs Weather Description')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65c5cd",
   "metadata": {},
   "source": [
    "### Statistical Tests\n",
    "#### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef779d6b",
   "metadata": {},
   "source": [
    "# Investigating the Shape of Data\n",
    "This section looks to explore the shape of the data by generating graphs. These graphs will focus on the number of calls per some unit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(data=df, x='date')\n",
    "ax.set_title('All Calls Over Time')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_xlabel('Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915bcecd",
   "metadata": {},
   "source": [
    "This graph shows all of the call types over time. What is interesting is that there appears to be a big gap around 2018 and smaller gaps in 2019 and 2021. There is a second big gap between 2021 and 2022 but not as bad as the 2018 gap. Another interesting observation is that it appears that overall call numbers is trending down. Looking deeper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd309a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=df, x='week')\n",
    "ax.set_title('All Calls Over Week of the Year')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_xlabel('Week of the Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8accc428",
   "metadata": {},
   "source": [
    "This graph shows a comparison between the number of calls recieved per week of the year. The number of calls looks to be consistent. There is one issue in that the data has 53 weeks each year. This should not be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06840e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=df[(df['year'] == 2017) & (df['month']==2)], x='day')\n",
    "ax.set_title('All Calls in February 2017')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_xlabel('Day of the Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e1707",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=df[(df['year'] == 2017) & (df['month']==12)], x='day')\n",
    "ax.set_title('All Calls in December 2017')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_xlabel('Day of the Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2967d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=df[(df['year'] == 2018) & (df['month']==1)], x='day')\n",
    "ax.set_title('All Calls in January 2018')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_xlabel('Day of the Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee0d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=df[(df['year'] == 2021) & (df['month']==2)], x='day')\n",
    "ax.set_title('All Calls in February 2021')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_xlabel('Day of the Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=df[(df['year'] == 2021) & (df['month']==8)], x='day')\n",
    "ax.set_title('All Calls in August 2021')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_xlabel('Day of the Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e7702",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=df[(df['year'] == 2021) & (df['month']==9)], x='day')\n",
    "ax.set_title('All Calls in September 2021')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_xlabel('Day of the Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=df[(df['year'] == 2021) & (df['month']==10)], x='day')\n",
    "ax.set_title('All Calls in October 2021')\n",
    "ax.set_ylabel('Number of Calls')\n",
    "ax.set_xlabel('Day of the Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568640dd",
   "metadata": {},
   "source": [
    "## TODO\n",
    "I emailed Nick to see if he can offer inisght here. At the moment, I'm guessing it's outage related - Chris\n",
    "## TODO\n",
    "Explain what each of the above graphs shows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7047cf24",
   "metadata": {},
   "source": [
    "# Building Models to Test if Prediction is Possible\n",
    "- models to test\n",
    "    - Random Forest\n",
    "    - SVM\n",
    "    - Logistic Regression\n",
    "- Graphs\n",
    "    - Recall vs. Precision Graph\n",
    "    - Confusion Matrix\n",
    "    - ROC Curve\n",
    "\n",
    "This section seeks to train models to answer the following research question:\n",
    "- Is it possible to predict the nature of a call based on its location and district?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38abccb8",
   "metadata": {},
   "source": [
    "List all of the categorical features and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6148183",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_name = 'top_natures'\n",
    "\n",
    "features = df.copy(deep=True)\n",
    "# features = features.drop(columns=[response_name], axis=1)\n",
    "\n",
    "response = df[response_name]\n",
    "\n",
    "# https://stackoverflow.com/questions/16453644/regression-with-date-variable-using-scikit-learn\n",
    "# drop date and datetime but keep the separated ones.\n",
    "to_drop = ['date', 'datetime', 'weekday', 'shots_nature', 'traffic_crime', 'weapon_crime', 'isdaytime', response_name]\n",
    "\n",
    "# features = features.drop(columns=['date', 'year', 'month', 'week', 'day', 'hour', 'weekday'])\n",
    "numeric_features = ['call_id', 'houseNumber', 'loc_id', 'tempC', 'windspeedKmph', \\\n",
    "    'winddirdegree', 'precipMM', 'humidity', 'visibilityKm', 'pressureMB',\\\n",
    "        'cloudcover', 'HeatIndexC', 'DewPointC', 'WindChillC', 'WindGustKmph',\\\n",
    "            'FeelsLikeC', 'uvIndex', 'year', 'month', 'week', 'day', 'hour'] # , 'date', 'year', 'month', 'week', 'day', 'hour', 'weekday']\n",
    "\n",
    "# features = features.drop(columns=['minNature', 'nature', 'traffic_crime', \n",
    "# 'weapon_crime', 'isdaytime',\n",
    "# 'primaryStreetSuffix', 'secondaryStreetName', 'secondaryStreetSuffix', 'district'])\n",
    "\n",
    "categorical_features = ['status', 'primaryStreetName', 'isCorner', \\\n",
    "    'primaryStreetSuffix', 'secondaryStreetName', 'secondaryStreetSuffix', 'top_districts']\n",
    "features = features.drop(columns=to_drop)\n",
    "# features = features.drop(columns=[response_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2840e3c",
   "metadata": {},
   "source": [
    "Next create the testing, training, and validation sets. The training and testing set sizes will be reduced since the overall number of data points exceedes four million.\n",
    "<!-- Some help from [stackoverflow](https://stackoverflow.com/a/38251213) was used. This will create a 60%, 20%, 20% split. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b084547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validate, test = np.split(df.sample(frac=1, random_state=42), \n",
    "# [int(.6*len(df)), int(.8*len(df))])\n",
    "train, test = train_test_split(df, test_size=0.005, train_size=0.1, stratify=df[response_name], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01321eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = train.drop(columns=[response_name], axis=1)\n",
    "# x_test = test.drop(columns=[response_name], axis=1)\n",
    "# x_validate = validate.drop(columns=[response_name], axis=1)\n",
    "x_train = train.drop(columns=to_drop, axis=1)\n",
    "x_test = test.drop(columns=to_drop, axis=1)\n",
    "# x_validate = validate.drop(columns=to_drop, axis=1)\n",
    "y_train =train[response_name]\n",
    "y_test = test[response_name]\n",
    "# y_validate = validate[response_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2330c2",
   "metadata": {},
   "source": [
    "Create the preprocessor pipeline for numeric and categorical features. This code comes from an in class example on the scat pipeline notebook presented during week 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cafb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26b9a09",
   "metadata": {},
   "source": [
    "Create different classifiers with and without PCA. Then define the grid search parameters and grid search sections. This code comes from the same in class example as the previous part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c347cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr_svd = Pipeline([(\"preprocessor\", preprocessor),\n",
    "\t\t\t('tSVD', TruncatedSVD(n_components=10)),\n",
    "\t\t\t('clf', LogisticRegression(random_state=42, solver='liblinear'))])\n",
    "\n",
    "pipe_rf_svd = Pipeline([(\"preprocessor\", preprocessor),\n",
    "\t\t\t('tSVD', TruncatedSVD(n_components=10)),\n",
    "\t\t\t('clf', RandomForestClassifier(random_state=42, n_jobs=-1))])\n",
    "\t\t\t\n",
    "# pipe_svm_svd = Pipeline([(\"preprocessor\", preprocessor),\n",
    "# \t\t\t('tSVD', TruncatedSVD(n_components=10)),\n",
    "# \t\t\t('clf', SVC(random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d54bd0",
   "metadata": {},
   "source": [
    "### Test the Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b216c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pipelines for ease of iteration\n",
    "grids = [pipe_lr_svd, pipe_rf_svd]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "grid_dict = {0: 'Logistic Regression w/tSVD', 1: 'Random Forest w/tSVD'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d80a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "\tprint('\\nEstimator: %s' % grid_dict[idx])\t\n",
    "\t# Fit grid search\t\n",
    "\tgs.fit(x_train, y_train)\n",
    "\t# # Best params\n",
    "\t# print('Best params: %s' % gs.best_params_)\n",
    "\t# # Best training data accuracy\n",
    "\t# print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "\t# # Predict on test data with best params\n",
    "\ty_pred = gs.predict(x_test)\n",
    "\t# Test data accuracy of model with best params\n",
    "\tprint('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "\t\n",
    "\t# Track best (highest test accuracy) model\n",
    "\tif accuracy_score(y_test, y_pred) > best_acc:\n",
    "\t\tbest_acc = accuracy_score(y_test, y_pred)\n",
    "\t\tbest_gs = gs\n",
    "\t\tbest_clf = idx\n",
    "print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_clf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f65385",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "It looks like the Random Forest with TruncatedSVD was the best predictor out of the tested models. The next step is to evaluate how the model performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6598a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_gs.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_pred, labels=best_gs.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_gs.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54ec16a",
   "metadata": {},
   "source": [
    "Unfortunatly, there are so many labels that the confusion matrix is somewhat illegible. This means test statistics will need to be relied upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "# from sklearn.metrics import roc_curve, plot_roc_curve, \n",
    "# precision_recall_curve, plot_precision_recall_curve\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print('Random Forest w/tSVD Accuracy = %.3f, Precision = %.3f, Recall = %.3f' % (accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b75020b",
   "metadata": {},
   "source": [
    "Based on the accuracy, precision, and recall of the model it appears like it is not possible to predict the nature of a call based on other factors about that call. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a96f42",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "- Analysis of results, further study, improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f71e78",
   "metadata": {},
   "source": [
    "# TODO Other:\n",
    "- Explanations of all data and graph outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ecbb87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1617da2f0a028b9e7fd5fffe443e8129e2ebb45766933769f8e579976b127668"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
